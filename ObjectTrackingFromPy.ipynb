{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e1f203b-347b-4900-91b4-17f99a6536aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "\n",
    "# Upload the classifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "import cv2\n",
    "# Import python libraries\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "# Import python libraries\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import tempfile\n",
    "\n",
    "\n",
    "#----Tracker,Detection, Classifier Model ---\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "def dprint(*args, **kwargs):\n",
    "        \"\"\"Debug print function using inbuilt print\n",
    "        Args:\n",
    "            args   : variable number of arguments\n",
    "            kwargs : variable number of keyword argument\n",
    "        Return:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        # print(*args, **kwargs)\n",
    "        pass\n",
    "\n",
    "class KalmanFilter(object):\n",
    "    \n",
    "        def __init__(self):\n",
    "            \"\"\"Initialize variable used by Kalman Filter class\n",
    "            Args:\n",
    "                None\n",
    "            Return:\n",
    "                None\n",
    "            \"\"\"\n",
    "            self.dt =  0.05 #0.005 # delta time\n",
    "    \n",
    "            self.A = np.array([[1, 0], [0, 1]])  # matrix in observation equations\n",
    "            self.u = np.zeros((2, 1))  # previous state vector\n",
    "    \n",
    "            # (x,y) tracking object center\n",
    "            self.b = np.array([[0], [255]])  # vector of observations\n",
    "    \n",
    "            self.P = np.diag((3.0, 3.0))  # indicates the confidence in the x and y positions\n",
    "            \n",
    "            self.F = np.array([[1.0, self.dt], [0.0, 1.0]])  # state transition mat\n",
    "    \n",
    "            self.Q = np.eye(self.u.shape[0])  # process noise matrix\n",
    "            self.R = np.eye(self.b.shape[0])  # observation noise matrix\n",
    "            self.lastResult = np.array([[0], [255]])\n",
    "    \n",
    "        def predict(self):\n",
    "            \"\"\"Predict state vector u and variance of uncertainty P (covariance).\n",
    "                where,\n",
    "                u: previous state vector\n",
    "                P: previous covariance matrix\n",
    "                F: state transition matrix\n",
    "                Q: process noise matrix\n",
    "            Equations:\n",
    "                u'_{k|k-1} = Fu'_{k-1|k-1}\n",
    "                P_{k|k-1} = FP_{k-1|k-1} F.T + Q\n",
    "                where,\n",
    "                    F.T is F transpose\n",
    "            Args:\n",
    "                None\n",
    "            Return:\n",
    "                vector of predicted state estimate\n",
    "            \"\"\"\n",
    "            # Predicted state estimate\n",
    "            self.u = np.round(np.dot(self.F, self.u))\n",
    "            # Predicted estimate covariance\n",
    "            self.P = np.dot(self.F, np.dot(self.P, self.F.T)) + self.Q\n",
    "            self.lastResult = self.u  # same last predicted result\n",
    "            return self.u\n",
    "    \n",
    "        def correct(self, b, flag):\n",
    "            \"\"\"Correct or update state vector u and variance of uncertainty P (covariance).\n",
    "            where,\n",
    "            u: predicted state vector u\n",
    "            A: matrix in observation equations\n",
    "            b: vector of observations\n",
    "            P: predicted covariance matrix\n",
    "            Q: process noise matrix\n",
    "            R: observation noise matrix\n",
    "            Equations:\n",
    "                C = AP_{k|k-1} A.T + R\n",
    "                K_{k} = P_{k|k-1} A.T(C.Inv)\n",
    "                u'_{k|k} = u'_{k|k-1} + K_{k}(b_{k} - Au'_{k|k-1})\n",
    "                P_{k|k} = P_{k|k-1} - K_{k}(CK.T)\n",
    "                where,\n",
    "                    A.T is A transpose\n",
    "                    C.Inv is C inverse\n",
    "            Args:\n",
    "                b: vector of observations\n",
    "                flag: if \"true\" prediction result will be updated else detection\n",
    "            Return:\n",
    "                predicted state vector u\n",
    "            \"\"\"\n",
    "    \n",
    "            if not flag:  # update using prediction\n",
    "                self.b = self.lastResult\n",
    "            else:  # update using detection\n",
    "                self.b = b\n",
    "            C = np.dot(self.A, np.dot(self.P, self.A.T)) + self.R\n",
    "            K = np.dot(self.P, np.dot(self.A.T, np.linalg.inv(C)))\n",
    "    \n",
    "            self.u = np.round(self.u + np.dot(K, (self.b - np.dot(self.A,\n",
    "                                                                  self.u))))\n",
    "            self.P = self.P - np.dot(K, np.dot(C, K.T))\n",
    "            self.lastResult = self.u\n",
    "            return self.u\n",
    "\n",
    "\n",
    "class Detectors(object):\n",
    "        \"\"\"Detectors class to detect objects in video frame\n",
    "        Attributes:\n",
    "            None\n",
    "        \"\"\"\n",
    "        def __init__(self):\n",
    "           \n",
    "    \n",
    "            \n",
    "            #self.model = YOLO(\"YOLO3.pt\")\n",
    "            self.model = YOLO(\"last.pt\")\n",
    "            \n",
    "            \n",
    "            # Data transforms (Including Data Augmentation)\n",
    "            self.transform = transforms.Compose([\n",
    "                    transforms.Resize(256),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                ])\n",
    "    \n",
    "            # Load pretrained ResNet18\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "            # Replace the final fully connected layer for binary classification\n",
    "            self.classifier = models.resnet18(pretrained=False)\n",
    "            num_ftrs = self.classifier.fc.in_features\n",
    "            self.classifier.fc = nn.Linear(num_ftrs, 2)\n",
    "    \n",
    "    \n",
    "            self.classifier.load_state_dict(torch.load(\"90F1ScoreModel.pth\", map_location=torch.device('cpu') ))\n",
    "            self.classifier.eval()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        def Detect(self, frame):\n",
    "            \"\"\"Detect objects in video frame using following pipeline\n",
    "                - Convert captured frame from BGR to GRAY\n",
    "                - Perform Background Subtraction\n",
    "                - Detect edges using Canny Edge Detection\n",
    "                  http://docs.opencv.org/trunk/da/d22/tutorial_py_canny.html\n",
    "                - Retain only edges within the threshold\n",
    "                - Find contours\n",
    "                - Find centroids for each valid contours\n",
    "            Args:\n",
    "                frame: single video frame\n",
    "            Return:\n",
    "                centers: vector of object centroids in a frame\n",
    "            \"\"\"\n",
    "    \n",
    "            \n",
    "            results = self.model(frame) #self.CLIENT.infer(frame, model_id=\"anthophora_bomboides-bees/2\")\n",
    "            # show contours of tracking objects\n",
    "            # cv2.imshow('Track Bugs', frame)\n",
    "            \n",
    "            \n",
    "            \n",
    "            results = results[0].boxes.xywh.numpy() #results[\"predictions\"]\n",
    "            print(results)\n",
    "            centers = []\n",
    "            classes = []\n",
    "            newImg = frame.copy()\n",
    "            for x , y, w ,h in results:\n",
    "                x1 = int(x - w / 2)\n",
    "                y1 = int(y - h/ 2)\n",
    "                x2 = int(x + w / 2)\n",
    "                y2 = int(y + h / 2)\n",
    "    \n",
    "                crop = frame[y1:y2,x1:x2,:]\n",
    "                \n",
    "                img_pil = Image.fromarray(crop)\n",
    "                \n",
    "                # Apply your transform\n",
    "                img_tensor = self.transform(img_pil)\n",
    "                \n",
    "                # Add batch dimension\n",
    "                img_tensor = img_tensor.unsqueeze(0)\n",
    "                \n",
    "                # Now pass it through your model\n",
    "                output = self.classifier(img_tensor)\n",
    "    \n",
    "                pollenBearing = np.argmax(output.detach().numpy())\n",
    "    \n",
    "                if pollenBearing:\n",
    "                    cv2.rectangle(newImg, (x1, y1), (x2, y2), (0,0,0), 2)\n",
    "                else: \n",
    "                    cv2.rectangle(newImg, (x1, y1), (x2, y2), (255,255,0), 2)\n",
    "                \n",
    "                \n",
    "                b = np.array([[x], [y]])\n",
    "                centers.append(b)\n",
    "                classes.append(pollenBearing)\n",
    "            \n",
    "            \n",
    "            return centers , newImg , classes\n",
    "            #return centers , frame , classes\n",
    "    \n",
    "    \n",
    "    # In[8]:\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "class Track(object):\n",
    "    \"\"\"Track class for every object to be tracked\n",
    "    Attributes:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, prediction, trackIdCount):\n",
    "        \"\"\"Initialize variables used by Track class\n",
    "        Args:\n",
    "            prediction: predicted centroids of object to be tracked\n",
    "            trackIdCount: identification of each track object\n",
    "        Return:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.firstDetection = np.asarray(prediction)\n",
    "        self.classes = []\n",
    "        self.track_id = trackIdCount  # identification of each track object\n",
    "        self.KF = KalmanFilter()  # KF instance to track this object\n",
    "        self.prediction = np.asarray(prediction)  # predicted centroids (x,y)\n",
    "        self.skipped_frames = 0  # number of frames skipped undetected\n",
    "        self.trace = []  # trace path\n",
    "\n",
    "\n",
    "class Tracker(object):\n",
    "    \"\"\"Tracker class that updates track vectors of object tracked\n",
    "    Attributes:\n",
    "        None\n",
    "    \"\"\"\n",
    "    #(160, 30, 5, 100)\n",
    "    def __init__(self, dist_thresh, max_frames_to_skip, max_trace_length,\n",
    "                 trackIdCount):\n",
    "        \"\"\"Initialize variable used by Tracker class\n",
    "        Args:\n",
    "            dist_thresh: distance threshold. When exceeds the threshold,\n",
    "                         track will be deleted and new track is created\n",
    "            max_frames_to_skip: maximum allowed frames to be skipped for\n",
    "                                the track object undetected\n",
    "            max_trace_lenght: trace path history length\n",
    "            trackIdCount: identification of each track object\n",
    "        Return:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.dist_thresh = dist_thresh\n",
    "        self.max_frames_to_skip = max_frames_to_skip\n",
    "        self.max_trace_length = max_trace_length\n",
    "        self.tracks = []\n",
    "        self.trackIdCount = trackIdCount\n",
    "\n",
    "    def Update(self, detections , classes):\n",
    "        \"\"\"Update tracks vector using following steps:\n",
    "            - Create tracks if no tracks vector found\n",
    "            - Calculate cost using sum of square distance\n",
    "              between predicted vs detected centroids\n",
    "            - Using Hungarian Algorithm assign the correct\n",
    "              detected measurements to predicted tracks\n",
    "              https://en.wikipedia.org/wiki/Hungarian_algorithm\n",
    "            - Identify tracks with no assignment, if any\n",
    "            - If tracks are not detected for long time, remove them\n",
    "            - Now look for un_assigned detects\n",
    "            - Start new tracks\n",
    "            - Update KalmanFilter state, lastResults and tracks trace\n",
    "        Args:\n",
    "            detections: detected centroids of object to be tracked\n",
    "        Return:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        # Create tracks if no tracks vector found\n",
    "        if (len(self.tracks) == 0):\n",
    "            for i in range(len(detections)):\n",
    "                track = Track(detections[i], self.trackIdCount)\n",
    "                self.trackIdCount += 1\n",
    "                self.tracks.append(track)\n",
    "\n",
    "        # Calculate cost using sum of square distance between\n",
    "        # predicted vs detected centroids\n",
    "        N = len(self.tracks)\n",
    "        M = len(detections)\n",
    "        cost = np.zeros(shape=(N, M))   # Cost matrix\n",
    "        for i in range(len(self.tracks)):\n",
    "            for j in range(len(detections)):\n",
    "                try:\n",
    "                    diff = self.tracks[i].prediction - detections[j]\n",
    "                    distance = np.sqrt(diff[0][0]**2 + diff[1][0]**2)\n",
    "                    cost[i][j] = distance\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        # Let's average the squared ERROR\n",
    "        cost = (0.5) * cost\n",
    "        # Using Hungarian Algorithm assign the correct detected measurements\n",
    "        # to predicted tracks\n",
    "        assignment = []\n",
    "        for _ in range(N):\n",
    "            assignment.append(-1)\n",
    "            \n",
    "        #find the optimal assignment of detections to tracks that minimizes the total cost.\n",
    "        row_ind, col_ind = linear_sum_assignment(cost) #\n",
    "        \n",
    "        for i in range(len(row_ind)): #for each track (existing)\n",
    "            assignment[row_ind[i]] = col_ind[i]\n",
    "            \n",
    "\n",
    "        # Identify tracks with no assignment, if any\n",
    "        un_assigned_tracks = []\n",
    "        for i in range(len(assignment)):\n",
    "            if (assignment[i] != -1):\n",
    "                # check for cost distance threshold.\n",
    "                # If cost is very high then un_assign (delete) the track\n",
    "                if (cost[i][assignment[i]] > self.dist_thresh):\n",
    "                    assignment[i] = -1\n",
    "                    un_assigned_tracks.append(i)\n",
    "                pass\n",
    "            else:\n",
    "                self.tracks[i].skipped_frames += 1\n",
    "\n",
    "        # If tracks are not detected for long time, remove them\n",
    "        del_tracks = []\n",
    "        for i in range(len(self.tracks)):\n",
    "            if (self.tracks[i].skipped_frames > self.max_frames_to_skip):\n",
    "                del_tracks.append(i)\n",
    "        if len(del_tracks) > 0:  # only when skipped frame exceeds max\n",
    "            for id in del_tracks:\n",
    "                if id < len(self.tracks):\n",
    "                    del self.tracks[id]\n",
    "                    del assignment[id]\n",
    "                else:\n",
    "                    dprint(\"ERROR: id is greater than length of tracks\")\n",
    "\n",
    "        # Now look for un_assigned detects\n",
    "        un_assigned_detects = []\n",
    "        for i in range(len(detections)):\n",
    "                if i not in assignment:\n",
    "                    un_assigned_detects.append(i)\n",
    "\n",
    "        # Start new tracks\n",
    "        if(len(un_assigned_detects) != 0):\n",
    "            for i in range(len(un_assigned_detects)):\n",
    "                track = Track(detections[un_assigned_detects[i]],\n",
    "                              self.trackIdCount)\n",
    "                self.trackIdCount += 1\n",
    "                self.tracks.append(track)\n",
    "\n",
    "        # Update KalmanFilter state, lastResults and tracks trace\n",
    "        for i in range(len(assignment)):\n",
    "            self.tracks[i].KF.predict()\n",
    "\n",
    "            if(assignment[i] != -1):\n",
    "                #if tracked instance\n",
    "                self.tracks[i].skipped_frames = 0\n",
    "                self.tracks[i].prediction = self.tracks[i].KF.correct( detections[assignment[i]], 1)\n",
    "            else:\n",
    "                #No new tracked instance\n",
    "                self.tracks[i].prediction = self.tracks[i].KF.correct( np.array([[0], [0]]), 0)\n",
    "\n",
    "            if(len(self.tracks[i].trace) > self.max_trace_length):\n",
    "                for j in range(len(self.tracks[i].trace) -\n",
    "                               self.max_trace_length):\n",
    "                    del self.tracks[i].trace[j]\n",
    "                    del self.tracks[i].classes[j]\n",
    "\n",
    "            self.tracks[i].trace.append(self.tracks[i].prediction)\n",
    "            self.tracks[i].classes.append(classes[assignment[i]])\n",
    "            self.tracks[i].KF.lastResult = self.tracks[i].prediction\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# set to 1 for pipeline images\n",
    "debug = 0\n",
    "\n",
    "\n",
    "\n",
    "# Import python libraries\n",
    "import cv2\n",
    "import copy\n",
    "import math\n",
    "# Variables for drawing\n",
    "drawing = False  # True if mouse is pressed\n",
    "ix, iy = -1, -1  # Initial x, y\n",
    "fx, fy = -1, -1  # Final x, y\n",
    "rectangle = None\n",
    "\n",
    "def is_inside(point, box):\n",
    "    x, y = point\n",
    "    x_min, y_min, x_max, y_max = box\n",
    "    return x_min <= x <= x_max and y_min <= y <= y_max\n",
    "\n",
    "def count_in_out_tracks(box, tracks):\n",
    "\n",
    "    in_bees = []\n",
    "    out_bees = []\n",
    "    in_pollen = []\n",
    "\n",
    "    for track in tracks:\n",
    "        trace = track.trace\n",
    "        \n",
    "        if not trace:\n",
    "            continue  # skip empty traces\n",
    "        \n",
    "        start_inside = is_inside(trace[0], box)\n",
    "        end_inside = is_inside(trace[-1], box)\n",
    "\n",
    "        if not start_inside and end_inside:\n",
    "            in_class = np.mean(track.classes)\n",
    "            if in_class > 0.4:\n",
    "                in_pollen.append(track.track_id)\n",
    "            else:\n",
    "                in_bees.append(track.track_id)\n",
    "            \n",
    "        elif start_inside and not end_inside:\n",
    "            out_bees.append(track.track_id)\n",
    "\n",
    "    return in_bees , in_pollen, out_bees\n",
    "\n",
    "\n",
    "def drawBox(img):\n",
    "    # Load image\n",
    "    clone = cv2.resize(img.copy(), None, fx=0.4, fy=0.4)\n",
    "\n",
    "    cv2.namedWindow('image')\n",
    "    cv2.setMouseCallback('image', draw_rectangle)\n",
    "\n",
    "    while True:\n",
    "        temp = clone.copy()\n",
    "\n",
    "        # Draw the rectangle while dragging\n",
    "        if drawing or rectangle:\n",
    "            cv2.rectangle(temp, (ix, iy), (fx, fy), (0, 255, 0), 2)\n",
    "\n",
    "        # Display helper text\n",
    "        cv2.putText(temp, \"Press [ENTER] to finalize coords\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow('image', temp)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == 13:  # Enter key\n",
    "            if rectangle:\n",
    "                x1, y1, x2, y2 = rectangle\n",
    "                x_min, x_max = sorted([x1, x2])\n",
    "                y_min, y_max = sorted([y1, y2])\n",
    "                break\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "# Mouse callback function\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "    global ix, iy, fx, fy, drawing, rectangle\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix, iy = x, y\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing:\n",
    "            fx, fy = x, y\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        fx, fy = x, y\n",
    "        rectangle = (ix, iy, fx, fy)  # Save rectangle\n",
    "        \n",
    "def getEntranceCoords(img):\n",
    "    # Load image\n",
    "    #clone = img.copy()\n",
    "    clone = cv2.resize(img.copy(), None, fx=0.4, fy=0.4)\n",
    "\n",
    "    ## Resize by scale factors\n",
    "    #resized_image = cv2.resize(image, None, fx=0.5, fy=0.5)  # Resize to 50% of original size\n",
    "\n",
    "\n",
    "    cv2.namedWindow('image')\n",
    "    cv2.setMouseCallback('image', draw_rectangle)\n",
    "\n",
    "    while True:\n",
    "        temp = clone.copy()\n",
    "\n",
    "        # Draw the rectangle while dragging\n",
    "        if drawing or rectangle:\n",
    "            cv2.rectangle(temp, (ix, iy), (fx, fy), (0, 255, 0), 2)\n",
    "\n",
    "        # Display helper text\n",
    "        cv2.putText(temp, \"Press [ENTER] to finalize coords\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow('image', temp)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == 13:  # Enter key\n",
    "            if rectangle:\n",
    "                x1, y1, x2, y2 = rectangle\n",
    "                x_min, x_max = sorted([x1, x2])\n",
    "                y_min, y_max = sorted([y1, y2])\n",
    "                break\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "\n",
    "import cv2\n",
    "import copy\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "skipFrames = 2\n",
    "# Variables for drawing\n",
    "drawing = False  # True if mouse is pressed\n",
    "ix, iy = -1, -1  # Initial x, y\n",
    "fx, fy = -1, -1  # Final x, y\n",
    "rectangle = None\n",
    "records = []\n",
    "\n",
    "# (Other functions like is_inside, count_in_out_tracks, draw_rectangle, getEntranceCoords)\n",
    "#tqdm\n",
    "import tempfile\n",
    "\n",
    "def process_video(uploaded_video):\n",
    "    beeCount = 0\n",
    "    beeInCount = 0\n",
    "    beeOutCount = 0\n",
    "\n",
    "    # Create opencv video capture object\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\") as tmp:\n",
    "        tmp.write(uploaded_video.read())\n",
    "        temp_video_path = tmp.name\n",
    "\n",
    "    # Open the video file with OpenCV\n",
    "    cap = cv2.VideoCapture(temp_video_path)\n",
    "\n",
    "    allTracks = set()\n",
    "    beesIn = set()\n",
    "    beesOut = set()\n",
    "    pollenIn = set()\n",
    "\n",
    "    # Create Object Detector\n",
    "    detector = Detectors()\n",
    "\n",
    "    # Create Object Tracker\n",
    "    tracker = Tracker(160, 1, 7, 100)\n",
    "\n",
    "    # Variables initialization\n",
    "    skip_frame_count = 0\n",
    "    track_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255), (255, 0, 255), (255, 127, 255),  (127, 0, 255), (127, 0, 127)]\n",
    "    pause = False\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # Frames per second\n",
    "    frame_number = 0  # To keep track of frames\n",
    "    \n",
    "    ret, prevframe = cap.read()\n",
    "    #prevframe = cv2.resize(prevframe.copy(), None, fx=0.6, fy=0.6)\n",
    "    \n",
    "    \n",
    "    #####################################################################################################\n",
    "    # Ask the user to specify the entrance of the beehive\n",
    "    box = getEntranceCoords(prevframe)\n",
    "    box2 =  drawBox(prevframe)\n",
    "    ####################################################################################################\n",
    "\n",
    "    # Initialize VideoWriter to save the video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Codec\n",
    "    out = cv2.VideoWriter('slow55.mp4', fourcc, fps, (int(cap.get(3)), int(cap.get(4))))  # (Width, Height)\n",
    "   \n",
    "    # Infinite loop to process video frames\n",
    "    while(True):\n",
    "\n",
    "        frame_number += 1  # Increment frame count\n",
    "        # Calculate time\n",
    "        seconds = frame_number / fps\n",
    "        minutes = int(seconds // 60)\n",
    "        seconds = int(seconds % 60)\n",
    "        # Format timestamp nicely\n",
    "        timestamp = f\"{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "        # Capture frame-by-frame\n",
    "        ret, currentFrame = cap.read()\n",
    "        currentFrame = cv2.resize(currentFrame.copy(), None, fx=0.4, fy=0.4)\n",
    "          # Draw entrance rectangle\n",
    "        cv2.rectangle(currentFrame, box2[:2], box2[2:], (255, 255, 255), -1)\n",
    "     \n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Make copy of original frame\n",
    "        orig_frame = copy.copy(currentFrame)\n",
    "\n",
    "        # Skip initial frames that display logo\n",
    "        if (skip_frame_count < 15):\n",
    "            skip_frame_count += 1\n",
    "            continue\n",
    "\n",
    "        # Detect and return centroids of the objects in the frame\n",
    "        centers, currentFrame, classes = detector.Detect(currentFrame)\n",
    "\n",
    "        # If centroids are detected then track them\n",
    "        if len(centers) > 0:\n",
    "            # Track object using Kalman Filter\n",
    "            tracker.Update(centers, classes)\n",
    "            beesTrackedIn, pollenTrackedIn, beesTrackedOut = count_in_out_tracks(box, tracker.tracks)\n",
    "\n",
    "            # Update bees and pollen counts\n",
    "            if len(beesTrackedIn) > 0:\n",
    "                for bee in beesTrackedIn:\n",
    "                    beesIn.add(bee)\n",
    "                    allTracks.add(bee)\n",
    "            if len(beesTrackedOut) > 0:\n",
    "                for bee in beesTrackedOut:\n",
    "                    beesOut.add(bee)\n",
    "                    allTracks.add(bee)\n",
    "            if len(pollenTrackedIn) > 0:\n",
    "                for pollen in pollenTrackedIn:\n",
    "                    pollenIn.add(pollen)\n",
    "                    allTracks.add(pollen)\n",
    "\n",
    "            records.append([timestamp, len(beesIn),len(pollenIn),len(beesOut)])\n",
    "\n",
    "        # Draw tracking lines for each object\n",
    "        for i in range(len(tracker.tracks)):\n",
    "            if len(tracker.tracks[i].trace) > 1:\n",
    "                for j in range(len(tracker.tracks[i].trace) - 1):\n",
    "                    x1 = tracker.tracks[i].trace[j][0][0]\n",
    "                    y1 = tracker.tracks[i].trace[j][1][0]\n",
    "                    x2 = tracker.tracks[i].trace[j+1][0][0]\n",
    "                    y2 = tracker.tracks[i].trace[j+1][1][0]\n",
    "                    clr = tracker.tracks[i].track_id % 9\n",
    "                    cv2.line(currentFrame, (int(x1), int(y1)), (int(x2), int(y2)),\n",
    "                             track_colors[clr], 2)\n",
    "                    mid_x = int((x1 + x2) / 2)\n",
    "                    mid_y = int((y1 + y2) / 2)\n",
    "                    cv2.putText(currentFrame, str(tracker.tracks[i].classes[j]), (mid_x, mid_y),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, track_colors[clr], 2)\n",
    "\n",
    "        # Add dashboard texts\n",
    "        cv2.putText(currentFrame, f\"Total Count: {len(allTracks)}\", (10, 40),  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)\n",
    "        cv2.putText(currentFrame, f\"Bees In: {len(beesIn)}\", (10, 70),  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)\n",
    "        cv2.putText(currentFrame, f\"Pollen In: {len(pollenIn)}\", (10, 100),  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)\n",
    "        cv2.putText(currentFrame, f\"Bees Out: {len(beesOut)}\", (10, 130),   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)\n",
    "        cv2.putText(currentFrame, f\"Time: {timestamp}\", (10, 160),  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)\n",
    "\n",
    "        # Draw entrance rectangle\n",
    "        cv2.rectangle(currentFrame, box[:2], box[2:], (255, 255, 255), 2)\n",
    "        cv2.imshow('frame',currentFrame)\n",
    "        # Write the frame to the video output\n",
    "        out.write(currentFrame)\n",
    "\n",
    "        # Slow down the FPS\n",
    "        cv2.waitKey(50)\n",
    "\n",
    "    # When everything done, release the capture and writer\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    df = pd.DataFrame(records, columns=[\"Time Stamp\", \"BeesIn\", \"pollenIn\", \"BeesOut\"])\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import base64\n",
    "\n",
    "# --- Streamlit Config ---\n",
    "st.set_page_config(\n",
    "    page_title=\"Beehive AI Monitor\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# --- Custom CSS Styling ---\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "    @import url('https://fonts.googleapis.com/css2?family=Pacifico&display=swap');\n",
    "\n",
    "    .stApp {\n",
    "        background-color: #FFF9C4; /* light yellow honey-themed */\n",
    "    }\n",
    "\n",
    "    .header-container {\n",
    "        display: flex;\n",
    "        justify-content: center; /* Center the logo horizontally */\n",
    "        padding: 10px 0;\n",
    "    }\n",
    "\n",
    "    .header-container img {\n",
    "        width: 700px; /* Bee Logo size */\n",
    "        height: auto;\n",
    "    }\n",
    "\n",
    "    .bee-text {\n",
    "        font-family: Pacifico;\n",
    "        font-size: 30px;\n",
    "        color: #F57F17;\n",
    "    }\n",
    "\n",
    "    .main-title {\n",
    "        font-size: 38px;\n",
    "        font-family: Pacifico;\n",
    "        color: #F57F17;\n",
    "        text-align: center;\n",
    "        padding: 10px;\n",
    "        background-color: #FFFDE7;\n",
    "        border-radius: 15px;\n",
    "        margin-top: 10px;\n",
    "    }\n",
    "\n",
    "    .section {\n",
    "        background-color: #FFFFFF;\n",
    "        padding: 20px;\n",
    "        border-radius: 15px;\n",
    "        margin-top: 10px;\n",
    "        box-shadow: 2px 2px 10px rgba(0,0,0,0.1);\n",
    "    }\n",
    "\n",
    "    .footer {\n",
    "        font-size: 14px;\n",
    "        text-align: center;\n",
    "        color: gray;\n",
    "        margin-top: 50px;\n",
    "    }\n",
    "\n",
    "    .bee-image {\n",
    "        width: 100% !important; /* Allow full width of the column */\n",
    "        max-width: 1500px; /* Maximum width to prevent excessive scaling */\n",
    "        height: auto;\n",
    "    }\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# --- Load and Display SVG ---\n",
    "def get_svg_base64(svg_path):\n",
    "    with open(svg_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode()\n",
    "\n",
    "def render_svg_image(svg_path, width=\"300px\", height=\"auto\"):\n",
    "    with open(svg_path, \"rb\") as f:\n",
    "        svg_bytes = f.read()\n",
    "        encoded = base64.b64encode(svg_bytes).decode()\n",
    "        img_tag = f\"<img src='data:image/svg+xml;base64,{encoded}' class='bee-image' />\"\n",
    "        st.markdown(img_tag, unsafe_allow_html=True)\n",
    "\n",
    "# --- App Title and Logo (Centered) ---\n",
    "logo_svg = get_svg_base64(\"bee_logo.svg\")\n",
    "header_html = f\"\"\"\n",
    "<div class=\"header-container\">\n",
    "    <img src=\"data:image/svg+xml;base64,{logo_svg}\" style=\"width:300px; height:auto;\" alt=\"Bee Logo\" />\n",
    "</div>\n",
    "\"\"\"\n",
    "st.markdown(header_html, unsafe_allow_html=True)\n",
    "\n",
    "st.markdown('<div class=\"main-title\"> SQU Beehive Monitor</div>', unsafe_allow_html=True)\n",
    "\n",
    "# --- Main Interface Section ---\n",
    "with st.container():\n",
    "    \n",
    "        st.subheader(\"📤 Upload Beehive Video\")\n",
    "\n",
    "    \n",
    "        uploaded_video = st.file_uploader(\"Upload your beehive video (MP4, AVI, MOV)\", type=[\"mp4\", \"avi\", \"mov\"])\n",
    "    \n",
    "        if uploaded_video:\n",
    "            st.video(uploaded_video)\n",
    "            st.success(\"✅ Video uploaded!\")\n",
    "    \n",
    "            if st.button(\"🚀 Start Analysis\", use_container_width=True):\n",
    "                    with st.spinner(\"Processing video...\"):\n",
    "                        log_data = process_video(uploaded_video)\n",
    "    \n",
    "                    st.success(\"✅ Analysis complete!\")\n",
    "                    st.markdown(\"### 📊 Bee Activity Log\")\n",
    "                    st.dataframe(log_data)\n",
    "    \n",
    "                    # Download button for Excel\n",
    "                    output_path = \"bee_activity_log.xlsx\"\n",
    "                    log_data.to_excel(output_path, index=False)\n",
    "                    with open(output_path, \"rb\") as f:\n",
    "                        st.download_button(\"⬇️ Download Excel Log\", f, file_name=\"bee_activity_log.xlsx\",use_container_width=True)\n",
    "    \n",
    "      \n",
    "\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "\n",
    "# --- Footer ---\n",
    "st.markdown('<div class=\"footer\">Made for Beekeepers </div>', unsafe_allow_html=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59dddbb-968b-49de-87b7-50a5a8658431",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622fffa6-2af6-4562-91ce-ca39e16bbcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
